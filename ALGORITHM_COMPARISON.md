# RAGFlow 算法对比与选择指南

## 1. 分块算法对比

### 算法特性对比表

| 特性 | naive_merge | hierarchical_merge | tree_merge |
|------|-----------|------------------|-----------|
| **复杂度** | O(n) | O(n log m) | O(n log m) |
| **内存占用** | 低 | 中 | 中 |
| **处理速度** | 快 | 中等 | 慢（需构建树） |
| **结构感知** | 否 | 是（5 种模式） | 是（全层级） |
| **重叠支持** | 是（可配置） | 有限 | 有限 |
| **适用文档** | 通用 | 结构化（论文/法律） | 极度嵌套 |
| **分块均匀性** | 好 | 优秀 | 优秀 |

### 算法流程对比

#### naive_merge 流程

```
输入文本：
"自然语言处理是人工智能的重要分支。
它处理文本数据。深度学习推动了发展。"

分隔符：\n。

步骤：
1. 按 delimiter 分割 → ["自然语言处理是...", "它处理文本数据。", "深度学习..."]
2. 遍历每个段落
3. Token 计数（使用 num_tokens_from_string）
4. 合并至 chunk_token_num 限制
5. 应用重叠（20% 时，从前一 chunk 末尾取部分内容）

结果：
Chunk 1: "自然语言处理是人工智能的重要分支。它处理文本数据。"
Chunk 2: "处理文本数据。深度学习推动了发展。"  # 重叠部分
```

#### hierarchical_merge 流程

```
输入文本（带结构）：
第一章 基础知识
  1.1 定义
    1.1.1 自然语言处理定义
    1.1.2 应用领域
  1.2 历史
第二章 技术方法
  2.1 传统方法
  2.2 深度学习

步骤：
1. 识别 bullet pattern（第N章/N.N.N 格式）
2. 为每行分配层级
   - 第一章 → level 0
   - 1.1 → level 1
   - 1.1.1 → level 2
   - 具体文本 → level 3
3. 按层级建立索引
   levels[0] = [0]        # 第一章位置
   levels[1] = [1, 4]     # 1.1, 1.2 位置
   levels[2] = [2, 3, 5]  # 1.1.1, 1.1.2, 2.1 位置
4. 二分查找构建 chunk 边界
   从 level 0 → level N，收集相关子内容

结果（depth=2）：
Chunk 1: [第一章] [1.1] [1.1.1内容] [1.1.2内容]
Chunk 2: [第一章] [1.2] [1.2内容]
Chunk 3: [第二章] [2.1] [2.1内容]
Chunk 4: [第二章] [2.2] [2.2内容]
```

### 选择指南

```
┌─ 文档类型 ──────────────────────────────────────┐
│                                                   │
├─ 新闻/博客 → naive_merge (快速、无结构)          │
│   参数: chunk_token_num=256, overlap=10%         │
│                                                   │
├─ 学术论文 → hierarchical_merge (章节感知)        │
│   参数: bullet=1, depth=3                        │
│   bullet=1: 阿拉伯编号 (1. 1.1 1.1.1)           │
│                                                   │
├─ 法律文件 → hierarchical_merge (条款编号)        │
│   参数: bullet=0, depth=2                        │
│   bullet=0: 中文编号 (第N条)                    │
│                                                   │
├─ 产品文档 → hierarchical_merge (目录结构)        │
│   参数: bullet=4, depth=3                        │
│   bullet=4: Markdown (#, ##, ###)               │
│                                                   │
└─ 复杂嵌套 → tree_merge (完全树形)                │
    参数: 递归层级定义                              │
```

---

## 2. 嵌入模型对比

### 性能矩阵

| 模型 | 维度 | 多语言 | 价格 | 延迟 | 准确度 |
|------|------|--------|------|------|--------|
| **OpenAI 3-small** | 1536 | 是 | $$$ | 50ms | ⭐⭐⭐⭐⭐ |
| **OpenAI 3-large** | 3072 | 是 | $$$$ | 100ms | ⭐⭐⭐⭐⭐ |
| **Jina v3** | 1024 | 是 | $$ | 100ms | ⭐⭐⭐⭐⭐ |
| **Cohere v3** | 1024 | 是 | $$ | 80ms | ⭐⭐⭐⭐ |
| **BGE-large** | 1024 | 是 | 免费 | 200ms | ⭐⭐⭐⭐ |
| **TEI (本地)** | 可配 | 是 | 免费 | 10ms | ⭐⭐⭐⭐ |
| **Ollama** | 可配 | 是 | 免费 | 50ms | ⭐⭐⭐ |

### 成本分析（1M tokens）

```
OpenAI 3-small:     $0.02
OpenAI 3-large:     $0.13
Jina v3:            $0.01-0.10 (按类型)
Cohere v3:          $0.10
BGE/TEI (本地):     $0 (基础设施成本)

成本效益：
高准确度优先  → OpenAI 3-small ($0.02)
成本敏感     → BGE-large (本地部署)
多语言优化   → Jina v3 ($0.05-0.10)
离线要求     → TEI 或 Ollama
```

### 选择决策树

```
是否需要本地部署？
├─ 是 → TEI (推荐，有 GPU) 或 Ollama (无 GPU)
│       成本: 硬件投资
│       准确度: ⭐⭐⭐⭐
│
└─ 否 → API 调用
    是否多语言？
    ├─ 是 → Jina v3 或 OpenAI 3
    │       精度: OpenAI > Jina
    │       成本: Jina < OpenAI
    │
    └─ 否 → OpenAI (英文专优) 或 Cohere
            精度: OpenAI >= Cohere
            成本: Cohere < OpenAI
```

---

## 3. 重排模型对比

### 模型性能评估

| 模型 | 类型 | 多语言 | 长文本 | 准确度 | 成本 |
|------|------|--------|--------|--------|------|
| **Cohere v3** | 向量感知 | 是 | 是 | ⭐⭐⭐⭐⭐ | $$$ |
| **Jina Reranker** | 交叉编码器 | 是 | 是 | ⭐⭐⭐⭐⭐ | $$$ |
| **NVIDIA E5** | 双编码器 | 是 | 是 | ⭐⭐⭐⭐ | $$ |
| **BGE-Reranker** | 开源 | 是 | 是 | ⭐⭐⭐⭐ | 免费 |
| **Qwen Reranker** | 中文优化 | 中文 | 是 | ⭐⭐⭐⭐ | $$ |
| **LLM-based** | 逻辑推理 | 是 | 有限 | ⭐⭐⭐⭐⭐ | $$$ |

### 应用场景对应

```
低成本场景(<100/天)
└─ BGE-Reranker (本地)
   优点: 开源、准确、支持中文
   缺点: 需要 GPU (4GB)

中等规模(100-10K/天)
├─ NVIDIA E5 (API)
│  优点: 性价比好，性能稳定
│  缺点: 准确度略低于 Cohere
│
└─ Cohere Reranker (API)
   优点: 最高准确度，向量感知
   缺点: 成本最高

大规模(>10K/天)
└─ 本地部署 BGE-Reranker
   优点: 零边际成本
   缺点: 初期投资大

中文优化场景
└─ Qwen Reranker (API)
   优点: 中文理解最优
   缺点: 仅支持中文
```

---

## 4. 向量DB对比

### 技术对比

| 指标 | Elasticsearch | Infinity | OpenSearch | Weaviate |
|------|---------------|----------|-----------|----------|
| **部署难度** | 中 | 低 | 中 | 中 |
| **学习曲线** | 陡峭 | 平缓 | 中等 | 陡峭 |
| **全文搜索** | 优秀 | 中等 | 优秀 | 差 |
| **向量检索** | 好 | 优秀 | 好 | 优秀 |
| **融合能力** | 优秀 | 优秀 | 优秀 | 一般 |
| **可扩展性** | 优秀 | 中等 | 优秀 | 优秀 |
| **内存占用** | 高 | 低 | 高 | 中 |
| **查询延迟** | 50-100ms | 10-20ms | 50-100ms | 30-50ms |
| **成本** | $$ | $ | $$$ | $$ |

### 选择建议

```
开发环境/POC
└─ Elasticsearch (学习资源多)
   或 Infinity (更轻量)

生产环境
├─ 优先 Infinity
│  原因: 轻量、快、成本低、向量特化
│
├─ 其次 Elasticsearch
│  原因: 生态完善、故障处理成熟
│
└─ 特殊需求（图谱）
   └─ Weaviate
      原因: 原生图支持，复杂查询
```

---

## 5. 混合检索配置对比

### 融合权重策略

```python
场景 1: 语义相似度为主（理解型查询）
权重配置: {"weights": "0.05,0.95"}  # 5% 全文 + 95% 向量
示例: "What is machine learning?"
分析:
  - 关键词匹配度低（很多相关词不会精确出现）
  - 向量表示能捕捉语义相似性
  - 结论: 向量权重高

场景 2: 精确查询与语义结合
权重配置: {"weights": "0.3,0.7"}   # 30% 全文 + 70% 向量
示例: "用户 ID 为 12345 的订单状态"
分析:
  - 关键词精确匹配很重要（ID、订单状态）
  - 向量也能理解"订单"的语义
  - 结论: 两者都重要

场景 3: 精确关键词为主（仓库检索）
权重配置: {"weights": "0.6,0.4"}   # 60% 全文 + 40% 向量
示例: "获取 MySQL 数据库配置"
分析:
  - "MySQL" 关键词必须精确匹配
  - 向量可以找到相关的数据库讨论
  - 结论: 全文优先，向量辅助

场景 4: 完全倒数排名融合（RRF）
权重配置: RRF 融合
示例: 多源数据融合
特点:
  - 排名位置权重（1/(k+rank)）
  - 不依赖分数量级
  - 最鲁棒但计算复杂
```

### 融合公式对比

```
加权和融合：
score_final = w1 × norm(score_sparse) + w2 × norm(score_dense)
优点: 直观、快速
缺点: 需要手动归一化

倒数排名融合（RRF）：
score_final = Σ(1/(k+rank_sparse_i)) + Σ(1/(k+rank_dense_i))
其中 k=60（常用值）
优点: 鲁棒，不需要分数归一化
缺点: 计算成本高，丧失分数信息

组织级聚合（Tag-based）：
score_final = Σ(score_chunk_i) for chunk_i ∈ 同一文档
再按文档排序
优点: 利用文档结构
缺点: 不适合多文档混合
```

---

## 6. 文本处理流程对比

### 分词算法对比

| 算法 | 复杂度 | 准确度 | 歧义处理 | 语言 |
|------|--------|--------|----------|------|
| **最大匹配** | O(n) | 中 | 无 | 中文 |
| **Trie树（双向）** | O(nm) | 中高 | DFS | 中文 |
| **HMM** | O(n) | 高 | 隐马尔可夫 | 中文 |
| **CRF** | O(n²) | 高 | 条件随机场 | 中文/英文 |
| **Stemming** | O(n) | 中 | 规则 | 英文 |
| **Lemmatization** | O(n log n) | 高 | 词表查询 | 英文 |

### RAGFlow 选择

**RAGFlow 采用：Trie 树 + Porter Stemming + WordNet**

```
中文处理：
输入：自然语言处理技术
    ↓
前向最大匹配（Trie）：自然|语言|处理|技术
    ↓
后向最大匹配（反向Trie）：自然|语言|处理|技术
    ↓
冲突歧义消解（DFS）：选择最优分割
    ↓
输出：[自然, 语言, 处理, 技术]

英文处理：
输入：The processing of natural language
    ↓
Stemming（Porter）：process of natur languag
    ↓
Lemmatization（WordNet）：process of natural language
    ↓
输出：[process, natural, language]
```

---

## 7. 性能优化对比

### 缓存策略

```
缓存层级          | 命中率 | 延迟  | 成本
━━━━━━━━━━━━━━━━━┿━━━━━━┿━━━━┿━━━━━
L1: 内存缓存      | 95%   | <1ms | 内存
L2: Redis 缓存   | 80%   | <10ms| CPU
L3: 向量DB 缓存 | 60%   | <50ms| IO
L4: 热启动       | 30%   | 100ms| 硬盘

推荐配置：
- 热词向量：内存 (LRU 1000 项)
- 查询结果：Redis (TTL 1 小时)
- 嵌入向量：向量DB (持久化)
```

### 批处理策略

```
批大小        | 吞吐量    | 延迟      | 显存
━━━━━━━━━━━━━┿━━━━━━━━━┿━━━━━━━━━┿━━━━━━
1 (单条)      | 16 req/s | <100ms   | 2GB
4             | 50 req/s | <200ms   | 3GB
16 (推荐)     | 160 req/s| <500ms   | 6GB
32            | 250 req/s| <1s      | 10GB
64+           | 饱和     | >2s      | 爆显存

RAGFlow 选择：batch_size=16
原因: 平衡吞吐量和延迟
```

### 查询优化对比

```
优化方法        | 准确度影响 | 性能提升 | 复杂度
━━━━━━━━━━━━━━┿━━━━━━━━━━┿━━━━━━━━┿━━━━━━
相似度自适应   | -2%        | -5%     | 低
中间重排        | 0%         | +50%    | 中
排名特征融合   | +5%        | +20%    | 高
索引预热        | 0%         | +30%    | 低
查询重写        | +3%        | +10%    | 高

RAGFlow 组合：
相似度自适应 (0.1→0.17) + 中间重排 (top 64)
效果：精准度 99%，速度快 50%
```

---

## 8. 实战选择矩阵

### 快速决策表

```
┌─────────────────────────────────────────────────────┐
│ 我应该选择什么组合?                                │
└─────────────────────────────────────────────────────┘

小规模项目 (<10K docs, <100 queries/day)
分块：naive_merge
嵌入：OpenAI 或 HuggingFace TEI
检索：Elasticsearch (8.x)
重排：不需要
成本：$20-100/月

│
├─ 中等规模项目 (10K-1M docs, 1K-10K queries/day)
├──分块：hierarchical_merge (有结构) 或 naive_merge
├──嵌入：Jina v3 或 OpenAI 3-small
├──检索：Infinity 或 Elasticsearch
├──重排：Token 相似度 + 简单排名特征
└──成本：$100-500/月

│
└─ 大规模项目 (>1M docs, >10K queries/day)
  分块：hierarchical_merge + 多粒度
  嵌入：本地 TEI + OpenAI (混合)
  检索：Infinity 集群
  重排：BGE-Reranker (本地) 或 Cohere
  成本：$1000+/月 (含基础设施)
```

---

## 参考资源

- **论文**：
  - Dense Passage Retrieval (DPR) - Karpukhin et al.
  - ColBERT - Omar Khattab
  - RankGPT - Xueguang Ma

- **基准**：
  - BEIR (Benchmark for Information Retrieval)
  - MS MARCO
  - Natural Questions

- **工具**：
  - Ranx (排序评估)
  - Pytrec_eval (TREC 评估)
  - LightRank (学习排序)

---

**最后更新**：2025-11-01
